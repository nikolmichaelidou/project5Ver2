{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/project5Ver2/jupyter_notebooks'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_dir = os.getcwd()\n",
    "work_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "my_data_dir = 'inputs/cherry-leaves'\n",
    "train_path = my_data_dir + '/train'\n",
    "val_path = my_data_dir + '/validation'\n",
    "test_path = my_data_dir + '/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old version is already available create a new version.\n"
     ]
    }
   ],
   "source": [
    "version = 'v2'\n",
    "file_path = f'outputs/{version}'\n",
    "\n",
    "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
    "    print('Old version is already available create a new version.')\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(name=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'inputs/cherry-leaves/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m labels \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(train_path)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m( \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProject Labels: \u001b[39m\u001b[39m{\u001b[39;00mlabels\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'inputs/cherry-leaves/train'"
     ]
    }
   ],
   "source": [
    "labels = os.listdir(train_path)\n",
    "print( f\"Project Labels: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'outputs/v1/image_shape.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [57], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m version \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mv1\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m image_shape \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(filename\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moutputs/\u001b[39m\u001b[39m{\u001b[39;00mversion\u001b[39m}\u001b[39;00m\u001b[39m/image_shape.pkl\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m image_shape\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[39m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[39mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[39mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'outputs/v1/image_shape.pkl'"
     ]
    }
   ],
   "source": [
    "version = 'v1'\n",
    "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
    "image_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of images in train, test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [58], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df_freq \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame([])\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m folder \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m     \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m labels:\n\u001b[1;32m      4\u001b[0m         df_freq \u001b[39m=\u001b[39m df_freq\u001b[39m.\u001b[39mappend(\n\u001b[1;32m      5\u001b[0m             pd\u001b[39m.\u001b[39mSeries(data\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mSet\u001b[39m\u001b[39m'\u001b[39m: folder,\n\u001b[1;32m      6\u001b[0m                             \u001b[39m'\u001b[39m\u001b[39mLabel\u001b[39m\u001b[39m'\u001b[39m: label,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m             ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         )\n\u001b[1;32m     12\u001b[0m         \u001b[39mprint\u001b[39m(\n\u001b[1;32m     13\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m* \u001b[39m\u001b[39m{\u001b[39;00mfolder\u001b[39m}\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(os\u001b[39m.\u001b[39mlistdir(my_data_dir\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m folder \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m label))\u001b[39m}\u001b[39;00m\u001b[39m images\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "df_freq = pd.DataFrame([])\n",
    "for folder in ['train', 'validation', 'test']:\n",
    "    for label in labels:\n",
    "        df_freq = df_freq.append(\n",
    "            pd.Series(data={'Set': folder,\n",
    "                            'Label': label,\n",
    "                            'Frequency': int(len(os.listdir(my_data_dir + '/' + folder + '/' + label)))}\n",
    "                      ),\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"* {folder} - {label}: {len(os.listdir(my_data_dir+'/'+ folder + '/' + label))} images\")\n",
    "\n",
    "print(\"\\n\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
    "plt.savefig(f'{file_path}/labels_distribution.png',\n",
    "            bbox_inches='tight', dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
    "                                          width_shift_range=0.10,\n",
    "                                          height_shift_range=0.10,\n",
    "                                          shear_range=0.1,\n",
    "                                          zoom_range=0.1,\n",
    "                                          horizontal_flip=True,\n",
    "                                          vertical_flip=True,\n",
    "                                          fill_mode='nearest',\n",
    "                                          rescale=1./255\n",
    "                                          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [64], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m  \u001b[39m# Set batch size\u001b[39;00m\n\u001b[1;32m      2\u001b[0m train_set \u001b[39m=\u001b[39m augmented_image_data\u001b[39m.\u001b[39mflow_from_directory(train_path,\n\u001b[0;32m----> 3\u001b[0m                                                      target_size\u001b[39m=\u001b[39mimage_shape[:\u001b[39m2\u001b[39m],\n\u001b[1;32m      4\u001b[0m                                                      color_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrgb\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m                                                      batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m      6\u001b[0m                                                      class_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                                      shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m                                                      )\n\u001b[1;32m     10\u001b[0m train_set\u001b[39m.\u001b[39mclass_indices\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_shape' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 20  # Set batch size\n",
    "train_set = augmented_image_data.flow_from_directory(train_path,\n",
    "                                                     target_size=image_shape[:2],\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     class_mode='binary',\n",
    "                                                     shuffle=True\n",
    "                                                     )\n",
    "\n",
    "train_set.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [65], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m validation_set \u001b[39m=\u001b[39m ImageDataGenerator(rescale\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m)\u001b[39m.\u001b[39mflow_from_directory(val_path,\n\u001b[0;32m----> 2\u001b[0m                                                                         target_size\u001b[39m=\u001b[39mimage_shape[:\u001b[39m2\u001b[39m],\n\u001b[1;32m      3\u001b[0m                                                                         color_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrgb\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                                                         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m      5\u001b[0m                                                                         class_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                                                                         shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      7\u001b[0m                                                                         )\n\u001b[1;32m      9\u001b[0m validation_set\u001b[39m.\u001b[39mclass_indices\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_shape' is not defined"
     ]
    }
   ],
   "source": [
    "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
    "                                                                        target_size=image_shape[:2],\n",
    "                                                                        color_mode='rgb',\n",
    "                                                                        batch_size=batch_size,\n",
    "                                                                        class_mode='binary',\n",
    "                                                                        shuffle=False\n",
    "                                                                        )\n",
    "\n",
    "validation_set.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [66], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m est_set \u001b[39m=\u001b[39m ImageDataGenerator(rescale\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m)\u001b[39m.\u001b[39mflow_from_directory(test_path,\n\u001b[0;32m----> 2\u001b[0m                                                                  target_size\u001b[39m=\u001b[39mimage_shape[:\u001b[39m2\u001b[39m],\n\u001b[1;32m      3\u001b[0m                                                                  color_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrgb\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                                                  batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m      5\u001b[0m                                                                  class_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                                                                  shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      7\u001b[0m                                                                  )\n\u001b[1;32m      9\u001b[0m test_set\u001b[39m.\u001b[39mclass_indices\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_shape' is not defined"
     ]
    }
   ],
   "source": [
    "est_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
    "                                                                 target_size=image_shape[:2],\n",
    "                                                                 color_mode='rgb',\n",
    "                                                                 batch_size=batch_size,\n",
    "                                                                 class_mode='binary',\n",
    "                                                                 shuffle=False\n",
    "                                                                 )\n",
    "\n",
    "test_set.class_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot augment train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [67], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     img, label \u001b[39m=\u001b[39m train_set\u001b[39m.\u001b[39mnext()\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(img\u001b[39m.\u001b[39mshape)  \u001b[39m# (1,256,256,3)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     plt\u001b[39m.\u001b[39mimshow(img[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    img, label = train_set.next()\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot augmented validation and test images\n",
    "\n",
    "for _ in range(3):\n",
    "    img, label = validation_set.next()\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for _ in range(3):\n",
    "    img, label = test_set.next()\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=train_set.class_indices,\n",
    "            filename=f\"{file_path}/class_indices.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "\n",
    "\n",
    "def create_tf_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "              input_shape=image_shape, activation='relu', ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
    "              input_shape=image_shape, activation='relu', ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
    "              input_shape=image_shape, activation='relu', ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tf_model().summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model for model training\n",
    "\n",
    "model = create_tf_model()\n",
    "model.fit(train_set,\n",
    "          epochs=25,\n",
    "          steps_per_epoch=len(train_set.classes) // batch_size,\n",
    "          validation_data=validation_set,\n",
    "          callbacks=[early_stop],\n",
    "          verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "\n",
    "model.save('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "losses[['loss', 'val_loss']].plot(style='.-')\n",
    "plt.title(\"Loss\")\n",
    "plt.savefig(f'{file_path}/model_training_losses.png',\n",
    "            bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.savefig(f'{file_path}/model_training_acc.png',\n",
    "            bbox_inches='tight', dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
